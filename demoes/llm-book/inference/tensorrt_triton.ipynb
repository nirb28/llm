{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nirb28/llm/blob/main/demoes/llm-book/inference/tensorrt_triton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3GsJ7kcaE-t"
      },
      "source": [
        "# **Inference with TensorRT**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tJlizmg-YCP"
      },
      "source": [
        "## YOLO-V5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ik8U7U8sbjkj",
        "outputId": "a3a0c638-538e-4e03-d9d7-c2328f8719ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (1.26.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Collecting torch-tensorrt\n",
            "  Downloading torch_tensorrt-2.6.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Collecting torch==2.6.0 (from torch-tensorrt)\n",
            "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting tensorrt<10.8.0,>=10.7.0.post1 (from torch-tensorrt)\n",
            "  Downloading tensorrt-10.7.0.post1.tar.gz (35 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorrt-cu12<10.8.0,>=10.7.0.post1 (from torch-tensorrt)\n",
            "  Downloading tensorrt_cu12-10.7.0.post1.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorrt-cu12-bindings<10.8.0,>=10.7.0 (from torch-tensorrt)\n",
            "  Downloading tensorrt_cu12_bindings-10.7.0.post1-cp311-none-manylinux_2_17_x86_64.whl.metadata (628 bytes)\n",
            "Collecting tensorrt-cu12-libs<10.8.0,>=10.7.0 (from torch-tensorrt)\n",
            "  Downloading tensorrt_cu12_libs-10.7.0.post1.tar.gz (710 bytes)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging>=23 in /usr/local/lib/python3.11/dist-packages (from torch-tensorrt) (24.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-tensorrt) (1.26.4)\n",
            "Requirement already satisfied: typing-extensions>=4.7.0 in /usr/local/lib/python3.11/dist-packages (from torch-tensorrt) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torch-tensorrt) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torch-tensorrt) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torch-tensorrt) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torch-tensorrt) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->torch-tensorrt)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->torch-tensorrt)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->torch-tensorrt)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->torch-tensorrt)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->torch-tensorrt)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->torch-tensorrt)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->torch-tensorrt)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->torch-tensorrt)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->torch-tensorrt)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch==2.6.0->torch-tensorrt)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torch-tensorrt) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torch-tensorrt) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->torch-tensorrt)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.2.0 (from torch==2.6.0->torch-tensorrt)\n",
            "  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torch-tensorrt) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torch-tensorrt) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->torch-tensorrt) (3.0.2)\n",
            "Downloading torch_tensorrt-2.6.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_34_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m101.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m113.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m96.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorrt_cu12_bindings-10.7.0.post1-cp311-none-manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: tensorrt, tensorrt-cu12, tensorrt-cu12-libs\n",
            "  Building wheel for tensorrt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt: filename=tensorrt-10.7.0.post1-py2.py3-none-any.whl size=42168 sha256=1b722a798bd09f9ccb763cfa48a7fc988e248b367e06025c8ae4e98fce3b407a\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/f9/fa/d8dc822675c08f0b9f87bb4f080164bb4cf206692e2e62c0ae\n",
            "  Building wheel for tensorrt-cu12 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt-cu12: filename=tensorrt_cu12-10.7.0.post1-py2.py3-none-any.whl size=17631 sha256=255732bbf380264934a9dbaa8b8d40a9baf1fff5c6273364749192b99761034b\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/95/0d/93bc3231ac7802cf65d5600a1848f0052c3b34bf77a8138c28\n",
            "  Building wheel for tensorrt-cu12-libs (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt-cu12-libs: filename=tensorrt_cu12_libs-10.7.0.post1-py2.py3-none-manylinux_2_17_x86_64.whl size=2069981220 sha256=ab4b8ef46a113f2e704b4c755c4db89789d70069c806d50683e17811060a09e2\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/37/a3/80b753dffe437ee9003d15cefa3dfb451ade6e484737f97379\n",
            "Successfully built tensorrt tensorrt-cu12 tensorrt-cu12-libs\n",
            "Installing collected packages: triton, tensorrt-cu12-bindings, nvidia-cusparselt-cu12, tensorrt-cu12, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tensorrt-cu12-libs, tensorrt, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torch-tensorrt\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu124\n",
            "    Uninstalling torch-2.5.1+cu124:\n",
            "      Successfully uninstalled torch-2.5.1+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\n",
            "torchvision 0.20.1+cu124 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\n",
            "fastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nvjitlink-cu12-12.4.127 tensorrt-10.7.0.post1 tensorrt-cu12-10.7.0.post1 tensorrt-cu12-bindings-10.7.0.post1 tensorrt-cu12-libs-10.7.0.post1 torch-2.6.0 torch-tensorrt-2.6.0 triton-3.2.0\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python\n",
        "!pip install numpy\n",
        "!pip install torch-tensorrt\n",
        "!pip install pandas\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4e419d7-4312-4a85-ff95-113fc2ba2efc",
        "id": "OaaLXkJP-YCR"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/hub.py:330: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  warnings.warn(\n",
            "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
        "\n",
        "# Use GPU for inference\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkqFbyfAcAbb",
        "outputId": "4a05c640-c0dd-4cb9-fa8b-cabc0ac292e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-02-28 13:45:22--  http://images.cocodataset.org/zips/val2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.43.217, 3.5.30.157, 52.216.208.41, ...\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.43.217|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 815585330 (778M) [application/zip]\n",
            "Saving to: ‘val2017.zip.3’\n",
            "\n",
            "val2017.zip.3         0%[                    ]   2.30M  1.54MB/s               ^C\n",
            "replace val2017/000000212226.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
          ]
        }
      ],
      "source": [
        "# Download COCO validation data set\n",
        "!wget http://images.cocodataset.org/zips/val2017.zip\n",
        "!unzip val2017.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jDTxc6b-YCS"
      },
      "outputs": [],
      "source": [
        "# Iterate through the images in the dataset\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "def prepare_images(image_paths):\n",
        "\n",
        "    images = []\n",
        "    for image_path in image_paths:\n",
        "      image = cv2.imread(image_path)\n",
        "\n",
        "      # Preprocess the image\n",
        "      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "      image = cv2.resize(image, (640, 640))\n",
        "\n",
        "      image = image.transpose((2, 0, 1)) # W, H, C => C, H, W\n",
        "      image = torch.from_numpy(image).to(device)\n",
        "      image = image.float() / 255.0 # Normalize [0;1]\n",
        "      images.append(image)\n",
        "\n",
        "    return images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "In8wg8ub-YCT"
      },
      "outputs": [],
      "source": [
        "# Load COCO dataset\n",
        "image_dir = 'val2017'\n",
        "image_paths = [os.path.join(image_dir, img) for img in os.listdir(image_dir)]\n",
        "\n",
        "# Only take a subset of COCO\n",
        "IMAGE_NUMS = 128\n",
        "images = prepare_images(image_paths[:IMAGE_NUMS])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAypt2mS-YCT"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def run_inference(model, images):\n",
        "  times = []\n",
        "  results = []\n",
        "  for image in images:\n",
        "    # Move image to GPU, if not already\n",
        "    image = image.unsqueeze(0)\n",
        "    image_gpu = image.to('cuda')\n",
        "\n",
        "    # Run inference with no gradient calculation\n",
        "    start = time.time()\n",
        "    with torch.no_grad():\n",
        "        result = model(image_gpu)\n",
        "\n",
        "    results.append(result)\n",
        "    times.append(time.time() - start)\n",
        "\n",
        "  return results, times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaKMmgfG-YCT",
        "outputId": "67e2fbfe-01ce-4ca2-c874-2fdc6218a9a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average inference time (s): 0.008198220282793045\n",
            "Average inference time (s): 0.006218124181032181\n",
            "Average inference time (s): 0.007922634482383728\n",
            "Average inference time (s): 0.008371112868189812\n",
            "Average inference time (s): 0.007605014368891716\n",
            "Average inference time (s): 0.005643885582685471\n",
            "Average inference time (s): 0.0056277308613061905\n",
            "Average inference time (s): 0.005955127999186516\n",
            "Average inference time (s): 0.010654594749212265\n",
            "Average inference time (s): 0.010228211060166359\n",
            "Mean average inference time (s): 0.007642465643584728\n"
          ]
        }
      ],
      "source": [
        "NUM_TRIALS = 10\n",
        "avgs = []\n",
        "\n",
        "for i in range(NUM_TRIALS):\n",
        "    results, times = run_inference(model, images)\n",
        "    avg = sum(times)/len(times)\n",
        "    print(\"Average inference time (s):\", avg)\n",
        "    avgs.append(avg)\n",
        "\n",
        "mat = sum(avgs)/NUM_TRIALS\n",
        "print(\"Mean average inference time (s):\", mat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKIN7zJi2kvY"
      },
      "source": [
        "# **Accelerating the model with TensorRT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnHe3ayI-YCU",
        "outputId": "7f40e332-dc07-42f9-a7c3-91279fb0adb0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/long/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py:100: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if self.dynamic or self.grid[i].shape[2:4] != x[i].shape[2:4]:\n",
            "/home/long/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py:100: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if self.dynamic or self.grid[i].shape[2:4] != x[i].shape[2:4]:\n",
            "WARNING: [Torch-TensorRT] - Trying to record the value 0 with the ITensor input_0 again.\n",
            "WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter\n",
            "WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter\n",
            "WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter\n",
            "WARNING: [Torch-TensorRT] - Unable to process input type of at::kLong, truncate type to at::kInt in scalar_to_tensor_util \n",
            "WARNING: [Torch-TensorRT] - Trying to record the value 213 with the ITensor (Unnamed Layer* 121) [ElementWise]_output again.\n",
            "WARNING: [Torch-TensorRT] - Unable to process input type of at::kLong, truncate type to at::kInt in scalar_to_tensor_util \n",
            "WARNING: [Torch-TensorRT] - Trying to record the value 224 with the ITensor (Unnamed Layer* 126) [ElementWise]_output again.\n",
            "WARNING: [Torch-TensorRT] - Unable to process input type of at::kLong, truncate type to at::kInt in scalar_to_tensor_util \n",
            "WARNING: [Torch-TensorRT] - Trying to record the value 53 with the ITensor (Unnamed Layer* 23) [ElementWise]_output again.\n",
            "WARNING: [Torch-TensorRT] - Unable to process input type of at::kLong, truncate type to at::kInt in scalar_to_tensor_util \n",
            "WARNING: [Torch-TensorRT] - Trying to record the value 64 with the ITensor (Unnamed Layer* 28) [ElementWise]_output again.\n",
            "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Int64 to Int32\n",
            "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Int64 to Int32\n",
            "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Int64 to Int32\n",
            "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Int64 to Int32\n",
            "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Int64 to Int32\n",
            "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Int64 to Int32\n"
          ]
        }
      ],
      "source": [
        "import torch_tensorrt\n",
        "\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "input_data = torch.randn(1, 3, 640, 640)\n",
        "\n",
        "\n",
        "trt_model = torch_tensorrt.compile(model, inputs=[input_data],\n",
        "                                   ir='ts',\n",
        "                                   enabled_precisions={torch.float32},\n",
        "                                   truncate_long_and_double=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2k98Ehd-YCU",
        "outputId": "f6f5a283-9e50-4f5c-823a-6aa35cfe8f12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorRT optimized\n",
            "Average inference time (s): 0.004738861694931984\n",
            "Average inference time (s): 0.003201013430953026\n",
            "Average inference time (s): 0.0034089460968971252\n",
            "Average inference time (s): 0.003065887838602066\n",
            "Average inference time (s): 0.002827117219567299\n",
            "Average inference time (s): 0.0027531571686267853\n",
            "Average inference time (s): 0.0029252376407384872\n",
            "Average inference time (s): 0.002684958279132843\n",
            "Average inference time (s): 0.0024376586079597473\n",
            "Average inference time (s): 0.0030416101217269897\n",
            "Mean average inference time (s): 0.0031084448099136354\n"
          ]
        }
      ],
      "source": [
        "print(\"TensorRT optimized\")\n",
        "\n",
        "avgs = []\n",
        "for i in range(NUM_TRIALS):\n",
        "    trt_results, trt_time = run_inference(trt_model, images)\n",
        "    avg = sum(trt_time)/len(images)\n",
        "    print(\"Average inference time (s):\", avg)\n",
        "    avgs.append(avg)\n",
        "\n",
        "trt_mat = sum(avgs)/NUM_TRIALS\n",
        "print(\"Mean average inference time (s):\", trt_mat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJi7IUa9-YCV",
        "outputId": "3475b7eb-7f85-496f-9c51-bd20c7612746"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Speed up: 2.4586139085406717\n"
          ]
        }
      ],
      "source": [
        "speed_up = mat / trt_mat\n",
        "print(\"Speed up:\", speed_up)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eyx4huY-YCV"
      },
      "source": [
        "# **Batching**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkHuPKut-YCV",
        "outputId": "9e430669-40af-47a1-a264-41a1fb883167"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/long/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py:100: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if self.dynamic or self.grid[i].shape[2:4] != x[i].shape[2:4]:\n",
            "/home/long/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py:100: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if self.dynamic or self.grid[i].shape[2:4] != x[i].shape[2:4]:\n",
            "WARNING:torch_tensorrt._compile:Input graph is a Torchscript module but the ir provided is default (dynamo). Please set ir=torchscript to suppress the warning. Compiling the module with ir=torchscript\n",
            "WARNING: [Torch-TensorRT] - Trying to record the value 0 with the ITensor input_0 again.\n",
            "WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter\n",
            "WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter\n",
            "WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter\n",
            "WARNING: [Torch-TensorRT] - Unable to process input type of at::kLong, truncate type to at::kInt in scalar_to_tensor_util \n",
            "WARNING: [Torch-TensorRT] - Trying to record the value 213 with the ITensor (Unnamed Layer* 121) [ElementWise]_output again.\n",
            "WARNING: [Torch-TensorRT] - Unable to process input type of at::kLong, truncate type to at::kInt in scalar_to_tensor_util \n",
            "WARNING: [Torch-TensorRT] - Trying to record the value 224 with the ITensor (Unnamed Layer* 126) [ElementWise]_output again.\n",
            "WARNING: [Torch-TensorRT] - Unable to process input type of at::kLong, truncate type to at::kInt in scalar_to_tensor_util \n",
            "WARNING: [Torch-TensorRT] - Trying to record the value 53 with the ITensor (Unnamed Layer* 23) [ElementWise]_output again.\n",
            "WARNING: [Torch-TensorRT] - Unable to process input type of at::kLong, truncate type to at::kInt in scalar_to_tensor_util \n",
            "WARNING: [Torch-TensorRT] - Trying to record the value 64 with the ITensor (Unnamed Layer* 28) [ElementWise]_output again.\n",
            "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size without setting allow_shape_tensors\n",
            "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Int64 to Int32\n",
            "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Int64 to Int32\n",
            "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size without setting allow_shape_tensors\n",
            "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Int64 to Int32\n",
            "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Int64 to Int32\n",
            "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size without setting allow_shape_tensors\n",
            "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Int64 to Int32\n",
            "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Int64 to Int32\n"
          ]
        }
      ],
      "source": [
        "import torch_tensorrt\n",
        "import torch\n",
        "\n",
        "# Example for dynamic batch size\n",
        "BATCH_SIZE = 16\n",
        "DYNAMIC_BATCH_ENABLED = True\n",
        "input_data = torch.randn(BATCH_SIZE, 3, 640, 640)\n",
        "\n",
        "if DYNAMIC_BATCH_ENABLED:\n",
        "    # Specify dynamic batch size\n",
        "    inputs = [torch_tensorrt.Input(\n",
        "        min_shape=[1, 3, 640, 640],\n",
        "        opt_shape=[BATCH_SIZE, 3, 640, 640],\n",
        "        max_shape=[32, 3, 640, 640],  # Example max batch size\n",
        "        dtype=torch.float32  # Ensure this matches your model's expected input type\n",
        "    )]\n",
        "else:\n",
        "    inputs = [input_data]\n",
        "\n",
        "ts = torch.jit.trace(model, input_data, strict=False)\n",
        "trt_model = torch_tensorrt.compile(ts,\n",
        "                                   inputs=inputs,\n",
        "                                   enabled_precisions={torch.float32},\n",
        "                                   truncate_long_and_double=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ubs9dS9-YCV"
      },
      "outputs": [],
      "source": [
        "def run_inference_in_batches(model, images, batch_size=BATCH_SIZE):\n",
        "    times = []\n",
        "    results = []\n",
        "\n",
        "    for i in range(0, len(images), batch_size):\n",
        "        batch_images = images[i:i + batch_size]\n",
        "\n",
        "        # Stack images to create a batch\n",
        "        batch = torch.stack(batch_images).to('cuda')\n",
        "\n",
        "        start = time.time()\n",
        "        with torch.no_grad():\n",
        "            result = model(batch)\n",
        "\n",
        "        results.append(result)\n",
        "        times.append(time.time() - start)\n",
        "\n",
        "    return results, times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LJ9IVYb-YCW",
        "outputId": "dfd88b42-785e-4ecd-ee0b-3d6c354e15b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorRT optimized - Batched  16\n",
            "Average inference time (s): 0.0031599905341863632\n",
            "Average inference time (s): 0.0016660261899232864\n",
            "Average inference time (s): 0.0016808975487947464\n",
            "Average inference time (s): 0.0016959533095359802\n",
            "Average inference time (s): 0.0017578788101673126\n",
            "Average inference time (s): 0.00174027681350708\n",
            "Average inference time (s): 0.00173121877014637\n",
            "Average inference time (s): 0.0017148610204458237\n",
            "Average inference time (s): 0.0016897749155759811\n",
            "Average inference time (s): 0.0017396770417690277\n",
            "Mean average inference time (s): 0.001857655495405197\n"
          ]
        }
      ],
      "source": [
        "print(\"TensorRT optimized - Batched \", BATCH_SIZE)\n",
        "avgs = []\n",
        "for i in range(NUM_TRIALS):\n",
        "    batched_results, batched_time = run_inference_in_batches(trt_model, images)\n",
        "    avg = sum(batched_time)/len(images)\n",
        "    print(\"Average inference time (s):\", avg)\n",
        "    avgs.append(avg)\n",
        "\n",
        "batched_mat = sum(avgs)/NUM_TRIALS\n",
        "print(\"Mean average inference time (s):\", batched_mat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ifa57_-T-YCW",
        "outputId": "03b6364d-57f9-4b83-8157-964f05445528"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4.114038185491294"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mat/batched_mat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRLpJ634-YCW",
        "outputId": "28b79fae-ac88-47a0-e01a-39322bf18cb4"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "speed_up_values = [mat / mat, mat / trt_mat, mat / batched_mat]\n",
        "labels = ['Baseline', 'TRT', 'Batched-TRT (16)']\n",
        "\n",
        "plt.bar(labels, speed_up_values, color=['blue', 'orange', 'green'])\n",
        "\n",
        "# Adding labels and title\n",
        "plt.ylabel('Speed Up in X')\n",
        "plt.title('Speed Up Comparison')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}