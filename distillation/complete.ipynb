{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b71c406-39c3-4463-889d-51a8f06f7450",
   "metadata": {},
   "source": [
    "# Language Model Distillation\n",
    "\n",
    "<img src=\"https://arxiv.org/html/2402.13116v3/x2.png\" width=600>\n",
    "\n",
    "Model Distillation is the process of using a large foundation model/high parameter LLMs to create annotated data for a specific task. That data is then used to fine tune a lightweight language model on the same task, allowing the smaller parameter model to perform as well as the foundation model at a fraction of the cost, energy consumption, and time. \n",
    "\n",
    "Per the paper [A Survey on Knowledge Distillation of Large Language Models](https://arxiv.org/pdf/2402.13116), \"This process is akin to transferring the ‘knowledge’ of a highly skilled teacher to a student, wherein the student (e.g., open-source LLM) learns to mimic the performance characteristics of the teacher (e.g., proprietary LLM).\"\n",
    "\n",
    "Most tasks that LLMs are applied to don't utilize the entire capability and power of a full size foundation model, so *why not distill down your one specific application into its own model?*\n",
    "\n",
    "**In this notebook we'll be:**\n",
    "1. Using [Llama 3.1 405B](https://huggingface.co/meta-llama/Meta-Llama-3.1-405B) to classify the sentiment of tweets, and\n",
    "2. Use that dataset to train [Roberta-base](https://huggingface.co/FacebookAI/roberta-base) a 125 million parameter language model.\n",
    "\n",
    "We end up with a model that performs with the same accuracy, at 0.03% of the size!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae98b73-8a34-4d48-80ff-dbe9bc05f7e7",
   "metadata": {},
   "source": [
    "---\n",
    "# Teacher Model Data Annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a002a4-19c9-4b7b-a3fe-aa8b0a6e7b33",
   "metadata": {},
   "source": [
    "Dataset consists of tweets with labeled sentiments, [mteb/tweet_sentiment_extraction](https://huggingface.co/datasets/mteb/tweet_sentiment_extraction). We will be using the tweet texts along with prompting to generate the \"knowledge\" annotation. This data is what becomes the training data for distillation.\n",
    "\n",
    "This would become simply fine-tuning/model training if the data is not generated by an LLM teacher! (i.e. human annotated data)\n",
    "\n",
    "For the sake of demonstration, assuming this data is not annoted already.\n",
    "\n",
    "### Importing Existing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "bcac2ecb-ff4c-4423-8304-0df8f2ccf43f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T00:01:15.820699Z",
     "start_time": "2024-08-10T00:01:09.071140Z"
    }
   },
   "source": [
    "# use hf datasets package to get the twitter sentiment data\n",
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"mteb/tweet_sentiment_extraction\")"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "7714b2cc-13bb-4ff5-a847-80b44880a926",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T00:01:15.837575Z",
     "start_time": "2024-08-10T00:01:15.823711Z"
    }
   },
   "source": [
    "ds['train'][0]"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a45182de-9013-4905-a0d1-fbc82e25262e",
   "metadata": {},
   "source": [
    "### Creating CSV\n",
    "\n",
    "Converting a subset to a local csv for easy manipulation and sampling.\n",
    "\n",
    "Train/split subset via HuggingFace dataset available [AdamLucek/twittersentiment-llama-3.1-405B-labels](https://huggingface.co/datasets/AdamLucek/twittersentiment-llama-3.1-405B-labels)"
   ]
  },
  {
   "cell_type": "code",
   "id": "49973fc8-f8ea-4bb8-ae8d-7abd8d244080",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T00:05:09.169529Z",
     "start_time": "2024-08-10T00:05:09.097544Z"
    }
   },
   "source": [
    "import csv\n",
    "import os\n",
    "from common.utils import get_project_root\n",
    "def convert_to_csv(ds, start_index, end_index, output_folder):\n",
    "\n",
    "    output_file = os.path.join(output_folder, f\"twittersentiment_{start_index}_{end_index}.csv\")\n",
    "    \n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = ['id', 'text', 'label', 'label_text']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        \n",
    "        writer.writeheader()\n",
    "        for i in range(start_index, min(end_index, len(ds['train']))):\n",
    "            row = ds['train'][i]\n",
    "            writer.writerow(row)\n",
    "    \n",
    "    print(f\"CSV file created: {output_file}\")\n",
    "\n",
    "# Usage\n",
    "start_index = 5001\n",
    "end_index = 6000\n",
    "output_folder = str(get_project_root())+\"/data/tweet_sentiment\"\n",
    "convert_to_csv(ds, start_index, end_index, output_folder)"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "70126ca8-e623-42fb-aa19-e33e5bfbd7c9",
   "metadata": {},
   "source": [
    "### Cleaning the CSV\n",
    "\n",
    "Simple script for dropping blank values that may break processing later on"
   ]
  },
  {
   "cell_type": "code",
   "id": "d126d914-1b31-4a08-a4c7-30e874f110c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T01:21:18.779651Z",
     "start_time": "2024-08-10T01:21:14.772642Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from common.utils import get_project_root\n",
    "# Load the CSV file\n",
    "unclean_df = pd.read_csv(str(get_project_root())+'/data/tweet_sentiment/twittersentiment_5001_6000.csv')\n",
    "\n",
    "# Remove rows where the 'text' label is blank\n",
    "df_cleaned = unclean_df[unclean_df['text'].notna() & (unclean_df['text'].str.strip() != '')]\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "df_cleaned.to_csv(str(get_project_root())+\"/data/tweet_sentiment/twittersentiment_5001_6000_cleaned.csv\", index=False)"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a9e0d352-306c-46e3-b73b-30428f52dbb5",
   "metadata": {},
   "source": [
    "---\n",
    "# Setting Up Teacher LLM \n",
    "\n",
    "[Llama 3.1 405B](https://ai.meta.com/blog/meta-llama-3-1/) explicitly states that *Our new model will enable the community to unlock new workflows, such as synthetic data generation and model distillation* in Meta's [release blog](https://ai.meta.com/blog/meta-llama-3-1/), so I wanted to use it as an example for distillation on this task, thus Llama 3.1 405B becomes the teacher model.\n",
    "\n",
    "The cheapest inference API i could find is via [Fireworks.ai](https://fireworks.ai/) which, at the time of making this, offer 1M Token `Input/Output` at `$3/$3` respectively. We'll use their integration with LangChain to instantiate."
   ]
  },
  {
   "cell_type": "code",
   "id": "28c3bf6e-ee39-4355-8129-f4ce0fdeb7c5",
   "metadata": {},
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "AZURE_OPENAI_API_KEY=os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_ENDPOINT=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "\n",
    "llm = AzureChatOpenAI (\n",
    "    api_version=\"2024-02-01\",\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    model=\"gpt-35-turbo\",\n",
    "    temperature=0.7\n",
    ")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T02:36:04.588105Z",
     "start_time": "2024-08-10T02:36:03.713330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "GROQ_API_KEY=os.getenv(\"GROQ_API_KEY\")\n",
    "llm = ChatGroq(\n",
    "    api_key=GROQ_API_KEY,\n",
    "    model=\"llama3-70b-8192\",\n",
    "    temperature=0.7\n",
    ")\n"
   ],
   "id": "1348fdb7695ea506",
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "11adb6b5-3080-45ad-b3a6-bc2e591214d2",
   "metadata": {},
   "source": [
    "### Prompting\n",
    "\n",
    "To ensure we give our teacher model the best opportunity, we'll be employing two techniques in our classification prompt:\n",
    "1. **Chain-of-Thought Reasoning:** Making the language model write a reasoning description to \"think\" through the problem before giving an answer\n",
    "2. **Few-shot Prompting:** Providing robust examples about your expectations of both performance and format to better guide the LLM.\n",
    "\n",
    "Examples taken from entries within the rows 7101-7200, which will not be used during training or for testing further on"
   ]
  },
  {
   "cell_type": "code",
   "id": "99c93237-b1ba-41d6-a4a0-194d99c5f969",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T02:36:06.894949Z",
     "start_time": "2024-08-10T02:36:06.888274Z"
    }
   },
   "source": [
    "tweet_sentiment_cot_prompt = \"\"\"\\\n",
    "You are a highly qualified expert trained to annotate machine learning training data.\n",
    "Your task is to briefly analyze the sentiment in the TEXT below from an social media manager perspective and then label it with only one the three labels:\n",
    "positive, negative, neutral.\n",
    "Base your label decision only on the TEXT and do not speculate e.g. based on prior knowledge about the context. \n",
    "You first reason step by step about the correct label and then return your label.\n",
    "You ALWAYS respond once in the following JSON format with brackets: {{\"reason\": \"...\", \"label\": \"...\"}}\n",
    "\n",
    "Examples:\n",
    "Text: Mode: Home Office\n",
    "JSON: {{\"reason\": \"The text is a factual statement about a work mode without expressing any emotion or opinion\", \"label\": \"neutral\"}}\n",
    "Text: oh oh oh are you offering to send ducks! I love love love confit duck\n",
    "JSON: {{\"reason\": \"The text expresses enthusiasm and love for confit duck, indicating a positive sentiment\", \"label\": \"positive\"}}\n",
    "Text: off to glue stuff onto poster\n",
    "JSON: {{\"reason\": \"The text is a simple statement of an action without any emotional context\", \"label\": \"neutral\"}}\n",
    "Text: Beautiful Day..takn it down twitters tell ALL mothers Happy Mothers Day\n",
    "JSON: {{\"reason\": \"The text describes a beautiful day and expresses positive wishes for Mother's Day\", \"label\": \"positive\"}}\n",
    "Text: Likewise. However, what was the comment about originally?\n",
    "JSON: {{\"reason\": \"The text is a neutral inquiry without expressing any particular sentiment\", \"label\": \"neutral\"}}\n",
    "Text: wished didnt spend money last night\n",
    "JSON: {{\"reason\": \"The text expresses regret about spending money, indicating a negative sentiment\", \"label\": \"negative\"}}\n",
    "Text: yo wake your **** up and go to work go get that paper u aint sick dont lie\n",
    "JSON: {{\"reason\": \"The text is aggressive and accusatory, suggesting a negative sentiment\", \"label\": \"negative\"}}\n",
    "Text: Such a beautiful morning\n",
    "JSON: {{\"reason\": \"The text expresses appreciation for the morning, indicating a positive sentiment\", \"label\": \"positive\"}}\n",
    "Text: Nooo...i forgot my calculator for physics oh well class is allmost over :3\n",
    "JSON: {{\"reason\": \"The text expresses initial disappointment about forgetting a calculator, indicating a negative sentiment\", \"label\": \"negative\"}}\n",
    "\"\"\""
   ],
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "21ee6aeb-dee8-48e8-889e-8dc5dabeefb7",
   "metadata": {},
   "source": [
    "and converting to an invokable chain via LangChain"
   ]
  },
  {
   "cell_type": "code",
   "id": "53896064-c5e8-423a-9160-40e38a80f22e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T02:36:08.687026Z",
     "start_time": "2024-08-10T02:36:08.670117Z"
    }
   },
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\", tweet_sentiment_cot_prompt\n",
    "        ),\n",
    "        (\n",
    "            \"human\", \"Your TEXT to analyse: {text}\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm | JsonOutputParser()"
   ],
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "a61e1b25-a5f4-40c6-9f22-b0f62ce76d10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T02:36:11.199640Z",
     "start_time": "2024-08-10T02:36:10.490065Z"
    }
   },
   "source": [
    "# Example\n",
    "#response = chain.invoke(\"Want to get a Blackberry but can`t afford it. Just watching the telly and relaxing. Hard sesion tomorrow.\")\n",
    "response = chain.invoke(\"But i dont mind the long line when theres a super cutie in front of me. Too bad he`s wearing a **** bracelet with a girls name on it\")\n",
    "\n",
    "response"
   ],
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "6a10351a-8f6c-4fab-bdb3-6a5076632294",
   "metadata": {},
   "source": [
    "### Annotation Script\n",
    "\n",
    "Now using our model + prompt to generate the annotations and combine them with the CSV. Error handling is generally due to the filtering that Llama 3.1 405B has to not generate answers when presented with innapropriate content.\n",
    "\n",
    "**NOTE:** This is roughly ~$10 of usage via API when ran over 5,000 examples. Run with caution! (when using fireworks API. I have pointed to Azure)"
   ]
  },
  {
   "cell_type": "code",
   "id": "da87583a-dbc5-452e-9d9d-c8769310c5f3",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-08-10T04:07:58.708417Z",
     "start_time": "2024-08-10T02:36:15.814790Z"
    }
   },
   "source": [
    "import json, csv\n",
    "\n",
    "def process_csv(input_file, output_file):\n",
    "    i = 0\n",
    "    with open(input_file, 'r', newline='', encoding='utf-8') as infile, \\\n",
    "         open(output_file, 'w', newline='', encoding='utf-8') as outfile:\n",
    "        \n",
    "        reader = csv.DictReader(infile)\n",
    "        fieldnames = reader.fieldnames + ['Llama_405B_reason', 'Llama_405B_label_text']\n",
    "        \n",
    "        writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        \n",
    "        for row in reader:\n",
    "            try:\n",
    "                # Invoke the chain with the text from the current row\n",
    "                response = chain.invoke({\"text\": row['text']})\n",
    "                result = json.loads(response) if isinstance(response, str) else response\n",
    "                \n",
    "                # Add new fields to the row\n",
    "                row['Llama_405B_reason'] = result['reason']\n",
    "                row['Llama_405B_label_text'] = result['label']\n",
    "                \n",
    "                # Write the updated row to the output file immediately\n",
    "                writer.writerow(row)\n",
    "                \n",
    "                # Flush the write buffer to ensure data is written to disk\n",
    "                outfile.flush()\n",
    "                \n",
    "                i+=1\n",
    "                print(f\"{i} - Processed and saved row with id: {row['id']}\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                # Error handling\n",
    "                print(f\"Error processing row with id {row.get('id', 'unknown')}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "    print(f\"Processing completed. Output saved to: {output_file}\")\n",
    "\n",
    "# Usage\n",
    "input_file = str(get_project_root())+\"/data/tweet_sentiment/twittersentiment_5001_6000_cleaned.csv\"\n",
    "output_file = str(get_project_root())+\"/data/tweet_sentiment/test.csv\"\n",
    "\n",
    "process_csv(input_file, output_file)  "
   ],
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a72bb998-334e-4021-b5df-cf59d98dce5e",
   "metadata": {},
   "source": [
    "### Calculate a Target Accuracy\n",
    "\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{\\text{Number of Correct Predictions}}{\\text{Total Number of Predictions}} \\times100\n",
    "$$\n",
    "\n",
    "Calculating a base accuracy of Llama 3.1 405B vs the expectation from the dataset's labels gives us a target accuracy to aim for when training our student language model"
   ]
  },
  {
   "cell_type": "code",
   "id": "d58be01e-e7b5-450a-9e44-cd5765ad73e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T04:07:58.750434Z",
     "start_time": "2024-08-10T04:07:58.713431Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load your updated CSV file\n",
    "df = pd.read_csv(str(get_project_root())+\"/data/tweet_sentiment/test.csv\")\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(df['label_text'], df['Llama_405B_label_text'])\n",
    "\n",
    "print(f\"Accuracy of Llama 3.1 405B: {accuracy:.2%}\")"
   ],
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "09cc7fae-19a6-43cc-9672-bdc5d25781b4",
   "metadata": {},
   "source": [
    "---\n",
    "# Training Student Model\n",
    "\n",
    "Our student model will be [FacebookAI/roberta-base](https://huggingface.co/FacebookAI/roberta-base), a 125 million parameter language model. We'll be fine tuning this model on our Llama 3.1 405B annotated data using [AutoTrain Adance](https://github.com/huggingface/autotrain-advanced), HuggingFaces' packaged opensource solution for lowcode model training. They make it as easy as possible to run on local hardware, or via GPU accelerator platforms like Google's Colab or [HuggingFace Spaces](https://huggingface.co/autotrain).\n",
    "\n",
    "We'll be using the *train* segment of the annotations generated, specifically the text from the original tweets and label as the Llama 3.1 405B generated label, passing in these hyperparameters (AutoTrain format)\n",
    "\n",
    "```python\n",
    "{\n",
    "  \"auto_find_batch_size\": \"false\",\n",
    "  \"eval_strategy\": \"epoch\",\n",
    "  \"mixed_precision\": \"fp16\",\n",
    "  \"optimizer\": \"adamw_torch\",\n",
    "  \"scheduler\": \"linear\",\n",
    "  \"batch_size\": \"16\",\n",
    "  \"early_stopping_patience\": \"5\",\n",
    "  \"early_stopping_threshold\": \"0.01\",\n",
    "  \"epochs\": \"5\",\n",
    "  \"gradient_accumulation\": \"1\",\n",
    "  \"lr\": \"0.00005\",\n",
    "  \"logging_steps\": \"-1\",\n",
    "  \"max_grad_norm\": \"1\",\n",
    "  \"max_seq_length\": \"128\",\n",
    "  \"save_total_limit\": \"1\",\n",
    "  \"seed\": \"42\",\n",
    "  \"warmup_ratio\": \"0.1\",\n",
    "  \"weight_decay\": \"0\"\n",
    "}\n",
    "```\n",
    "\n",
    "Final trained model published at [AdamLucek/roberta-llama3.1405B-twitter-sentiment](https://huggingface.co/AdamLucek/roberta-llama3.1405B-twitter-sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2865a04-9705-4445-9bb0-2dc111d51ffd",
   "metadata": {},
   "source": [
    "---\n",
    "# Testing Out the Fine Tuned Model\n",
    "\n",
    "We'll be using [HuggingFace's Transformers Package Pipelines](https://huggingface.co/docs/transformers/en/main_classes/pipelines) to easily load and run inference using our trained model"
   ]
  },
  {
   "cell_type": "code",
   "id": "02d0f3cb-e68c-4714-a3a9-0b3d4785ddd5",
   "metadata": {},
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Create sentiment Analysis pipeline\n",
    "classifier = pipeline(\"sentiment-analysis\", model=\"AdamLucek/roberta-llama3.1405B-twitter-sentiment\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "b98a86f1-e322-4abf-9eab-1cfefe925dcb",
   "metadata": {},
   "source": [
    "classifier(\"Want to get a Blackberry but can`t afford it. Just watching the telly and relaxing. Hard sesion tomorrow.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "e38c6ee8-9ec3-488b-b0a1-5491b0d18beb",
   "metadata": {},
   "source": [
    "---\n",
    "# Visualizing Accuracy\n",
    "\n",
    "Now to calculate and compare our fine tuned model's accuracy to compare to LLama 3.1 405B. For fun, also ran tests using [GPT-4o-Mini](https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/) and a [generalized multilingual sentiment model of similar size](https://huggingface.co/lxyuan/distilbert-base-multilingual-cased-sentiments-student)."
   ]
  },
  {
   "cell_type": "code",
   "id": "24aaa1c1-f499-4486-8583-a0e0c880d082",
   "metadata": {},
   "source": [
    "# Calculate accuracy\n",
    "result_df = pd.read_csv(\"/Users/alucek/Documents/Jupyter_Notebooks/synthetic_data/tweet_sentiment/total_tests.csv\")\n",
    "\n",
    "llama31_405B_accuracy = accuracy_score(result_df['label_text'], result_df['Llama_405B_label_text'])\n",
    "gpt4omini_accuracy = accuracy_score(result_df['label_text'], result_df['GPT4o_mini_label'])\n",
    "ft_roberta = accuracy_score(result_df['label_text'], result_df['Roberta_FT'])\n",
    "multilingual = accuracy_score(result_df['label_text'], result_df['ML_Roberta'])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "e65df45a-a658-4cb6-a157-5d7656915f75",
   "metadata": {},
   "source": [
    "### Accuracy Graph"
   ]
  },
  {
   "cell_type": "code",
   "id": "ffaa51ca-f77d-49ba-9dbd-740f8eba9570",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data\n",
    "models = ['LLama 3.1 405B', 'GPT-4o-Mini', 'Multilingual-Roberta', 'Fine Tuned Roberta']\n",
    "accuracies = [llama31_405B_accuracy, gpt4omini_accuracy, multilingual, ft_roberta]\n",
    "\n",
    "# Convert accuracies to percentages\n",
    "percentages = [acc * 100 for acc in accuracies]\n",
    "\n",
    "# Combine models and percentages into a list of tuples, sort by accuracy in descending order\n",
    "sorted_data = sorted(zip(models, percentages), key=lambda x: x[1], reverse=True)\n",
    "sorted_models, sorted_percentages = zip(*sorted_data)\n",
    "\n",
    "# Create bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(sorted_models, sorted_percentages, color=['#cde8f4', '#d6f5bf', '#fdd1d1', '#e3d9f0'], edgecolor='black', linewidth=1)\n",
    "plt.title(\"Accuracy of Models on Twitter Sentiment Classification\", fontsize=16)\n",
    "plt.xlabel(\"Model\", fontsize=12)\n",
    "plt.ylabel(\"Accuracy (%)\", fontsize=12)\n",
    "plt.ylim(0, 100)  # Set y-axis range from 0 to 100%\n",
    "\n",
    "# Add value labels on top of each bar\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, height,\n",
    "             f'{height:.2f}%',\n",
    "             ha='center', va='bottom')\n",
    "\n",
    "# Display\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "066be671-731b-45ee-bd4f-62fe5c6958a9",
   "metadata": {},
   "source": [
    "Roughly the same performance at **0.03%** the size!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239fe7eb-76c1-4239-8efc-d284bc32b281",
   "metadata": {},
   "source": [
    "### Count of Sentiments\n",
    "\n",
    "Also interesting to consider the distribution of sentiment labels across these models"
   ]
  },
  {
   "cell_type": "code",
   "id": "b67a0124-1b19-4639-9d88-ec13bb188e31",
   "metadata": {},
   "source": [
    "# List of models and their corresponding label columns\n",
    "models = {\n",
    "    'Llama 3.1 405B': 'Llama_405B_label_text',\n",
    "    'Roberta FineTune': 'Roberta_FT',\n",
    "    'Multilingual Distilbert': 'ML_Roberta',\n",
    "    'GPT 4o Mini': 'GPT4o_mini_label'\n",
    "}\n",
    "\n",
    "# Calculating counts\n",
    "label_counts = {model: {'positive': 0, 'neutral': 0, 'negative': 0} for model in models.keys()}\n",
    "for model, column in models.items():\n",
    "    label_counts[model]['positive'] = result_df[result_df[column] == 'positive'].shape[0]\n",
    "    label_counts[model]['neutral'] = result_df[result_df[column] == 'neutral'].shape[0]\n",
    "    label_counts[model]['negative'] = result_df[result_df[column] == 'negative'].shape[0]\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "counts_df = pd.DataFrame(label_counts).T\n",
    "\n",
    "# Plotting with outlines\n",
    "ax = counts_df.plot(\n",
    "    kind='bar', \n",
    "    stacked=True, \n",
    "    figsize=(10, 7), \n",
    "    color=['#b3e8d1', '#fccbb2', '#c7d4eb'],\n",
    "    edgecolor='black'\n",
    ")\n",
    "\n",
    "# Add counts on the bars\n",
    "for p in ax.patches:\n",
    "    width, height = p.get_width(), p.get_height()\n",
    "    x, y = p.get_xy() \n",
    "    ax.text(x + width/2, \n",
    "            y + height/2, \n",
    "            f'{int(height)}', \n",
    "            ha='center', \n",
    "            va='center')\n",
    "\n",
    "plt.title('Label Counts per Model')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title='Label')\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "691afcdf-45b4-4644-aa23-36ac591b2244",
   "metadata": {},
   "source": [
    "---\n",
    "# Addtional Notes: \n",
    "\n",
    "\n",
    "Consider the costs:\n",
    "* ~\\$0.08 for gpt4o via OpenAI\n",
    "* ~$1.80 for Llama 3.1 405B via Fireworks\n",
    "\n",
    "And consider the time cost too! Much slower inference with the foundational models compared to the distilled language model.\n",
    "\n",
    "Note that we are not aiming for higher accuracy here, rather a standard metric to assess our fine tuned model to see if it performs now as well as the foundation model\n",
    "\n",
    "And a big shoutout to Moritz Laurer for the https://huggingface.co/blog/synthetic-data-save-costs blog, much of which the primary methodology that guided this notebook was heavily inspired by."
   ]
  },
  {
   "cell_type": "code",
   "id": "2d1e4432-4024-4638-bd95-73ec4060b4db",
   "metadata": {},
   "source": [],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
